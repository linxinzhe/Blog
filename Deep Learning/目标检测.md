今天的这篇是对吴恩达的深度学习微专业的第四节课卷积神经网络的第三周的目标检测的总结。

普通的卷积神经网络我们用来识别一张图片是什么东西。但是有些时候我们需要知道这个物体在哪，也就是能识别出这个物体并且知道它的坐标(x,y)和长宽。

要能识别物体在哪，神经网络用带有坐标和长宽的标签的大量的这类物体做数据，用神经网络预测的点的位置和长宽的均方误差来训练得到的。

也可以同样的道理去训练一个识别人脸的特征（比如眼角和嘴角的位置）的神经网络。

明白了原理，我们就能做一个图像里的目标检测了，原理其实是用训练好的识别物体的神经网络，以一个小框去框出来的图片作为输入，一个框一个框的去扫描整个图像，知道找到这个框里有这个物体，以及它的坐标。

但是，用框去一个个扫并计算，相对于一个大图像被切割成很多相互间有非常多重复像素的图片，非常耗费计算性能。

因此，我们对整张大图谱直接输入神经网络去计算出它的卷积的最终结果，这个卷积结果的中的每个像素的值，从数学意义上看可以认为是，分别框出来的小图像输入神经网络后最终得到的预测值，这样大大提高了计算的效率。依然有个缺点就是，识别这个目标的边框可能不够精确。

YOLO算法可以解决这个边框的问题。我们以路上的目标检测为例，它把一个大图像划分成比如3x3的区域，整个图形输入神经网络，做卷积，每个区域都会对应一个8维向量（是否有物体，x轴位置，y轴位置，长，宽，是否是行人，是否是车，是否是摩托），最终是一个完整的3x3x8维向量，而看某个区域的8维向量结果可以知道，其中有某个物体，且它的边框是多少。

衡量一个目标检测是否符合标准，就看神经网络识别后的框和数据标注的框的交并比，也就是两者框的交集除以两者框的并集。

这里可能会碰到多次检测的问题，就是在目标附近的几个格子都会认为它检测到了目标，这时候应用非极大值抑制的算法，选出概率最大的格子，并把其他交并比很高的格子抑制（这一步交并比的判断，是因为有可能一个图像里有多个目标被检测出来，利用交并比可以只抑制一个目标附近多余的检测，而不能把其他目标的检测都被你抑制了）。不同类别的目标检测，如车和人，抑制分别跑，一共跑两次。


